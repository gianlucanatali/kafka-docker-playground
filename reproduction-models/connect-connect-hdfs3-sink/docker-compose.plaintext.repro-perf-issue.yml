---
  version: '3.5'
  services:
    # https://github.com/big-data-europe/docker-hadoop/tree/2.0.0-hadoop3.1.2-java8

    namenode:
      image: bde2020/hadoop-namenode:2.0.0-hadoop3.1.2-java8
      hostname: namenode
      container_name: namenode
      volumes:
        - namenode:/hadoop/dfs/name
      environment:
        - CLUSTER_NAME=test
      env_file:
        - ../../reproduction-models/connect-connect-hdfs3-sink/hadoop.env

    datanode:
      image: bde2020/hadoop-datanode:2.0.0-hadoop3.1.2-java8
      hostname: datanode
      container_name: datanode
      volumes:
        - datanode:/hadoop/dfs/data
      env_file:
        - ../../reproduction-models/connect-connect-hdfs3-sink/hadoop.env
      environment:
        SERVICE_PRECONDITION: "namenode:9870"

    resourcemanager:
      image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.1.2-java8
      hostname: resourcemanager
      container_name: resourcemanager
      environment:
        SERVICE_PRECONDITION: "namenode:9870 datanode:9864"
      env_file:
        - ../../reproduction-models/connect-connect-hdfs3-sink/hadoop.env

    nodemanager:
      image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.1.2-java8
      hostname: nodemanager
      container_name: nodemanager
      environment:
        SERVICE_PRECONDITION: "namenode:9870 datanode:9864 resourcemanager:8088"
      env_file:
        - ../../reproduction-models/connect-connect-hdfs3-sink/hadoop.env

    historyserver:
      image: bde2020/hadoop-historyserver:2.0.0-hadoop3.1.2-java8
      hostname: historyserver
      container_name: historyserver
      volumes:
        - hadoop_historyserver:/hadoop/yarn/timeline
      environment:
        SERVICE_PRECONDITION: "namenode:9870 datanode:9864 resourcemanager:8088"
      env_file:
        - ../../reproduction-models/connect-connect-hdfs3-sink/hadoop.env

    hive-server:
      hostname: hive-server
      container_name: hive-server
      image: vdesabou/hive:3.1.2-postgresql-metastore # https://github.com/vdesabou/docker-hive
      env_file:
        - ../../reproduction-models/connect-connect-hdfs3-sink/hadoop-hive.env
      environment:
        HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
        SERVICE_PRECONDITION: "hive-metastore:9083"

    hive-metastore:
      hostname: hive-metastore
      container_name: hive-metastore
      image: vdesabou/hive:3.1.2-postgresql-metastore # https://github.com/vdesabou/docker-hive
      env_file:
        - ../../reproduction-models/connect-connect-hdfs3-sink/hadoop-hive.env
      command: /opt/hive/bin/hive --service metastore
      environment:
        SERVICE_PRECONDITION: "namenode:9870 datanode:9864 hive-metastore-postgresql:5432"
      ports:
        - "9083:9083"

    hive-metastore-postgresql:
      hostname: hive-metastore-postgresql
      container_name: hive-metastore-postgresql
      image: bde2020/hive-metastore-postgresql:3.1.0

    presto-coordinator:
      hostname: presto-coordinator
      container_name: presto-coordinator
      image: shawnzhu/prestodb:0.181
      ports:
        - "18080:8080"

    connect:
      build:
        context: ../../reproduction-models/connect-connect-hdfs2-sink/jprofiler
        args:
          TAG_BASE: ${TAG_BASE}
      depends_on:
        - nodemanager
        - historyserver
        - datanode
        - resourcemanager
        - namenode
        - hive-server
        - presto-coordinator
        - hive-metastore
      # VisualVM
      ports:
      - "8849:8849"
      - "11002:11002"
      volumes:
        - ../../ksqldb/benchmarking-scenarios/schemas:/tmp/schemas
      environment:
        CONNECT_PLUGIN_PATH: /usr/share/confluent-hub-components/confluentinc-kafka-connect-hdfs3,/usr/share/confluent-hub-components/confluentinc-kafka-connect-datagen
        # VisualVM
        # https://gist.github.com/Kevin-Lee/cbfbde89d68299304b1b1a2e6371fe06#visualvm-with-docker
        # 1/ File -> Add JMX Connection...
        # 2/ Enter the host and port (e.g. localhost:11002)
        # JProfiler
        # Open New Session->Attach to an already running HotSpot JVM and profile it->127.0.0.1 8849
        KAFKA_OPTS:   -Dcom.sun.management.jmxremote=true
                      -Dcom.sun.management.jmxremote.port=11002
                      -Dcom.sun.management.jmxremote.authenticate=false
                      -Dcom.sun.management.jmxremote.ssl=false
                      -Dcom.sun.management.jmxremote.local.only=false
                      -Dcom.sun.management.jmxremote.rmi.port=11002
                      -Djava.rmi.server.hostname=localhost
                      -agentpath:/tmp/jprofiler12.0.2/bin/linux-x64/libjprofilerti.so=port=8849,nowait

  volumes:
    datanode:
    namenode:
    hadoop_historyserver:

  networks:
    default:
        name: mynetwork